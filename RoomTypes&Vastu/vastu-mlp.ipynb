{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":7679260,"sourceType":"datasetVersion","datasetId":4480069}],"dockerImageVersionId":30648,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"!pip install torch_geometric -q","metadata":{"execution":{"iopub.status.busy":"2024-03-13T13:50:17.397276Z","iopub.execute_input":"2024-03-13T13:50:17.397725Z","iopub.status.idle":"2024-03-13T13:50:31.962155Z","shell.execute_reply.started":"2024-03-13T13:50:17.397684Z","shell.execute_reply":"2024-03-13T13:50:31.960932Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"import pickle\nwith open('/kaggle/input/vastu-house-clean-data/vastu_clean_data.pkl', 'rb') as f:\n    loaded_data = pickle.load(f)\nprint(len(loaded_data))","metadata":{"execution":{"iopub.status.busy":"2024-03-13T13:50:38.077657Z","iopub.execute_input":"2024-03-13T13:50:38.078045Z","iopub.status.idle":"2024-03-13T13:50:41.249519Z","shell.execute_reply.started":"2024-03-13T13:50:38.078014Z","shell.execute_reply":"2024-03-13T13:50:41.248349Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"80788\n","output_type":"stream"}]},{"cell_type":"code","source":"from collections import defaultdict, Counter\nfrom torch_geometric.data import Data\nfrom torch_geometric.data import Dataset\nimport torch\nimport numpy as np\nimport pickle\n\n\nclass FloorplanGraphDataset(Dataset):\n    def __init__(self, path, split=None):\n        super(FloorplanGraphDataset, self).__init__()\n        self.path = path\n        with open(self.path, 'rb') as f:\n            loaded_data = pickle.load(f)\n        self.subgraphs = loaded_data\n        self.subgraphs = self.filter_graphs(self.subgraphs)\n        if split=='train':\n            self.subgraphs = self.subgraphs[:120000]\n        elif split=='test':\n            self.subgraphs = self.subgraphs[120000:]    \n        num_nodes = defaultdict(int)\n        for g in self.subgraphs:\n            labels = g[0] \n            if len(labels) > 0:\n                num_nodes[len(labels)] += 1\n        print(f'Number of graphs: {len(self.subgraphs)}')\n        print(f'Number of graphs by rooms: {num_nodes}')\n        \n    def len(self):\n        return len(self.subgraphs)\n\n    def get(self, index, bbs=False):\n        graph = self.subgraphs[index]\n        labels = np.array(graph[3])\n        room_categories=graph[0]\n        orientation=graph[2]\n        rooms_bbs = np.array(graph[1])\n#         edge2node = [item for sublist in graph[3] for item in sublist]\n#         node_doors = np.array(edge2node)[graph[4]]\n#         doors_count = Counter(node_doors)\n        features = []\n        rooms_bbs_new = []\n        for i, bb in enumerate(rooms_bbs):\n            x0, y0 = bb[0], bb[1]\n            x1, y1 = bb[2], bb[3]\n            xmin, ymin = min(x0, x1), min(y0, y1)\n            xmax, ymax = max(x0, x1), max(y0, y1)\n            l, b = xmax - xmin, ymax - ymin\n            area = l*b\n            if l<b:\n                l, b = b, l\n            features.append([room_categories[i],orientation[i]]) \n            rooms_bbs_new.append(np.array([xmin, ymin, xmax, ymax]))\n        rooms_bbs = np.stack(rooms_bbs_new)\n        intersect = self.intersect(rooms_bbs,rooms_bbs)\n#         for i in range(len(rooms_bbs)):\n#             for j in range(i+1,len(rooms_bbs)):\n#                 if intersect[i,j]>0.7*intersect[j,j]:\n#                     if intersect[i,i]>intersect[j,j]: #is i a parent\n#                         features[i][6] = 1\n#                         features[j][5] = 1\n#                     else:   # i is child\n#                         features[i][5] = 1\n#                         features[j][6] = 1\n#                 if intersect[i,j]>0.7*intersect[i,i]:\n#                     if intersect[j,j]>intersect[i,i]: \n#                         features[j][6] = 1\n#                         features[i][5] = 1\n#                     else:\n#                         features[j][5] = 1\n#                         features[i][6] = 1\n\n        rooms_bbs = rooms_bbs/256.0\n\n        tl = np.min(rooms_bbs[:, :2], 0)\n        br = np.max(rooms_bbs[:, 2:], 0)\n        shift = (tl+br)/2.0 - 0.5\n        rooms_bbs[:, :2] -= shift\n        rooms_bbs[:, 2:] -= shift\n        tl -= shift\n        br -= shift\n        edges = self.build_graph(rooms_bbs) \n#         labels = labels - 1\n#         labels[labels>=5] = labels[labels>=5] - 1\n        x = torch.tensor(features, dtype=torch.float)\n        edge_index = torch.tensor(edges.T, dtype=torch.long)\n        y = torch.tensor(labels, dtype=torch.long)\n        d = Data(x=x, edge_index=edge_index, y=y)\n        if bbs:\n            return d, rooms_bbs\n        return d\n\n    def build_graph(self, bbs):\n        edges = []\n        for k in range(len(bbs)):\n            for l in range(len(bbs)):\n                if l > k:\n                    bb0 = bbs[k]\n                    bb1 = bbs[l]\n                    if self.is_adjacent(bb0, bb1):\n                        edges.append([k, l])\n                        edges.append([l, k])\n        edges = np.array(edges)\n        return edges\n\n    def filter_graphs(self, graphs):\n        new_graphs = []\n        for g in graphs:       \n            labels = g[0]\n            rooms_bbs = g[1]\n            # discard broken samples\n            check_none = np.sum([bb is None for bb in rooms_bbs])\n            #check_node = np.sum([nd == 0 for nd in labels])\n            if (len(labels) < 2) or (check_none > 0):\n                continue\n            new_graphs.append(g)\n        return new_graphs\n\n    def is_adjacent(self, box_a, box_b, threshold=0.03):\n        \n        x0, y0, x1, y1 = box_a\n        x2, y2, x3, y3 = box_b\n\n        h1, h2 = x1-x0, x3-x2\n        w1, w2 = y1-y0, y3-y2\n\n        xc1, xc2 = (x0+x1)/2.0, (x2+x3)/2.0\n        yc1, yc2 = (y0+y1)/2.0, (y2+y3)/2.0\n\n        delta_x = np.abs(xc2-xc1) - (h1 + h2)/2.0\n        delta_y = np.abs(yc2-yc1) - (w1 + w2)/2.0\n\n        delta = max(delta_x, delta_y)\n\n        return delta < threshold\n\n    def intersect(self, A,B):\n        A, B = A[:,None], B[None]\n        low = np.s_[...,:2]\n        high = np.s_[...,2:]\n        A,B = A.copy(),B.copy()\n        A[high] += 1; B[high] += 1\n        intrs = (np.maximum(0,np.minimum(A[high],B[high])\n                            -np.maximum(A[low],B[low]))).prod(-1)\n        return intrs #/ ((A[high]-A[low]).prod(-1)+(B[high]-B[low]).prod(-1)-intrs)","metadata":{"execution":{"iopub.status.busy":"2024-03-13T13:50:50.398911Z","iopub.execute_input":"2024-03-13T13:50:50.399288Z","iopub.status.idle":"2024-03-13T13:50:54.107409Z","shell.execute_reply.started":"2024-03-13T13:50:50.399262Z","shell.execute_reply":"2024-03-13T13:50:54.106539Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"MOD_ROOM_CLASS = {0: \"Living room\", \n                1: \"Master oom\",\n                2: \"Kitchen\",\n                3: \"Bathroom\",\n                4: \"Dining room\",\n                5: \"Child room\",\n                6: \"Study room\",\n                7: \"Second room\",\n                8: \"Guest room\",\n                9: \"Balcony\",\n                10: \"Entrance\",\n                11: \"Storage\",\n                12: \"Wall-in\",\n                 13:\"Front door\"}\ndef visualize(d, bbs=None):\n    G = to_networkx(d, to_undirected=True)\n    plt.figure(figsize=(7,7))\n    plt.axis('off')\n    labels = {i: MOD_ROOM_CLASS[int(d.y[i])] for i in range(len(d.y))}\n    c = plt.get_cmap('Dark2').colors\n    color = [c[i] for i in d.y]\n    nx.draw_networkx(G, pos=nx.spring_layout(G, seed=42), with_labels=True, labels=labels, node_color=color, cmap='Dark2')\n    plt.show()\n    if bbs is not None:\n        plt.figure(figsize=(7,7))\n        for i, (xmin, ymin, xmax, ymax) in enumerate(bbs):\n            rect = patches.Rectangle((xmin, ymin), xmax-xmin, ymax-ymin, edgecolor='k', facecolor=c[d.y[i]], alpha=0.9)\n            plt.gca().add_patch(rect)\n        plt.show()","metadata":{"execution":{"iopub.status.busy":"2024-03-13T13:50:54.109378Z","iopub.execute_input":"2024-03-13T13:50:54.110293Z","iopub.status.idle":"2024-03-13T13:50:54.119949Z","shell.execute_reply.started":"2024-03-13T13:50:54.110256Z","shell.execute_reply":"2024-03-13T13:50:54.119088Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib.patches as patches\nimport torch\nfrom torch_geometric.utils import to_networkx\nimport networkx as nx\n#from dataset import MOD_ROOM_CLASS\n\ndevice = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\ndef accuracy(model, dataloader):\n    correct = 0\n    num_nodes = 0\n    model.to(device)\n    model.eval()\n    for data in dataloader:\n        data = data.to(device)\n        out = model(data.x, data.edge_index)\n        pred = out.argmax(1)\n        correct += sum(pred==data.y)\n        num_nodes += data.num_nodes\n    return (correct/num_nodes).item()","metadata":{"execution":{"iopub.status.busy":"2024-03-13T13:50:54.121307Z","iopub.execute_input":"2024-03-13T13:50:54.121719Z","iopub.status.idle":"2024-03-13T13:50:54.428318Z","shell.execute_reply.started":"2024-03-13T13:50:54.121689Z","shell.execute_reply":"2024-03-13T13:50:54.427362Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"device","metadata":{"execution":{"iopub.status.busy":"2024-03-13T13:50:54.429949Z","iopub.execute_input":"2024-03-13T13:50:54.430285Z","iopub.status.idle":"2024-03-13T13:50:54.437052Z","shell.execute_reply.started":"2024-03-13T13:50:54.430260Z","shell.execute_reply":"2024-03-13T13:50:54.436082Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"device(type='cuda')"},"metadata":{}}]},{"cell_type":"code","source":"import torch\nfrom torch.nn import Linear\nimport torch.nn.functional as F\n\nclass Model(torch.nn.Module):\n\n    def __init__(self, layer_type, n_hidden=2):\n        super(Model, self).__init__()\n        torch.manual_seed(42)\n        self.is_mlp = True if layer_type.__name__=='Linear' else False\n        self.layer1 = layer_type(2, 16)\n        self.layer2 = torch.nn.ModuleList()\n        for _ in range(n_hidden-1):\n            self.layer2.append(layer_type(16,16))\n        self.classifier = Linear(16, 8)\n\n    def forward(self, x, edge_index):\n        h = self.layer1(x) if self.is_mlp else self.layer1(x, edge_index)\n        h = F.relu(h)\n        for layer in self.layer2:\n            h = layer(h) if self.is_mlp else layer(h, edge_index)\n            h = F.relu(h)\n        out = self.classifier(h)\n        return out","metadata":{"execution":{"iopub.status.busy":"2024-03-13T13:51:06.608084Z","iopub.execute_input":"2024-03-13T13:51:06.608440Z","iopub.status.idle":"2024-03-13T13:51:06.618759Z","shell.execute_reply.started":"2024-03-13T13:51:06.608414Z","shell.execute_reply":"2024-03-13T13:51:06.617687Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"import torch\nimport numpy as np\n#from dataset import FloorplanGraphDataset\n#from utils import  accuracy\n#from model import Model\nfrom torch.nn import Linear\nfrom torch_geometric.data import DataLoader\nfrom torch_geometric.nn import SAGEConv, GATConv, GCNConv, TAGConv\nimport pathlib\n#import argparse\n\nmodel_type = 'mlp'  # 'mlp', 'gcn', 'gat', 'sage', 'tagcn'\nhidden_layers = 2\nnum_epochs = 100\nlearning_rate = 0.004\nstep_size = 10\ngamma = 0.8\nbatch_size = 128\noutpath = '/kaggle/working/results'\ndataset_file = '/kaggle/input/vastu-house-clean-data/vastu_clean_data.pkl'\nmodels = {\n    'mlp': Linear,\n    'gcn': GCNConv,\n    'gat': GATConv,\n    'sage': SAGEConv,\n    'tagcn': TAGConv,\n}\ndevice = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\nprint(device)\n\noutpath = pathlib.Path(outpath)\noutpath.mkdir(parents=True, exist_ok=True)\n\ntorch.manual_seed(42)\nmodel = Model(layer_type=models[model_type], n_hidden=hidden_layers)\nprint(model)\nmodel = model.to(device)","metadata":{"execution":{"iopub.status.busy":"2024-03-13T13:59:20.618806Z","iopub.execute_input":"2024-03-13T13:59:20.619663Z","iopub.status.idle":"2024-03-13T13:59:20.630656Z","shell.execute_reply.started":"2024-03-13T13:59:20.619629Z","shell.execute_reply":"2024-03-13T13:59:20.629721Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"cuda\nModel(\n  (layer1): Linear(in_features=2, out_features=16, bias=True)\n  (layer2): ModuleList(\n    (0): Linear(in_features=16, out_features=16, bias=True)\n  )\n  (classifier): Linear(in_features=16, out_features=8, bias=True)\n)\n","output_type":"stream"}]},{"cell_type":"code","source":"dataset = FloorplanGraphDataset(path=dataset_file, split=None)\ntrain = [dataset[i].to(device) for i in range(65000)]\ntrainloader = DataLoader(train, batch_size=batch_size, shuffle=True)\ntrainloader2 = DataLoader(train, batch_size=65000)\ntest = [dataset[i].to(device) for i in range(65000,80788)]\ntestloader = DataLoader(test, batch_size=15788)","metadata":{"execution":{"iopub.status.busy":"2024-03-13T13:59:22.622088Z","iopub.execute_input":"2024-03-13T13:59:22.622462Z","iopub.status.idle":"2024-03-13T14:00:23.361553Z","shell.execute_reply.started":"2024-03-13T13:59:22.622434Z","shell.execute_reply":"2024-03-13T14:00:23.360775Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"Number of graphs: 80788\nNumber of graphs by rooms: defaultdict(<class 'int'>, {7: 25104, 8: 29278, 9: 20364, 6: 5788, 5: 254})\n","output_type":"stream"}]},{"cell_type":"code","source":"num_epochs = num_epochs\nlr = learning_rate\nstep_size = step_size\ngamma = gamma\noutpath = '/kaggle/working/'\n\ncriterion = torch.nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=lr)\nexp_lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=step_size, gamma=gamma)\n\nloss_ep = []\nte_acc_ep = []\ntr_acc_ep = []","metadata":{"execution":{"iopub.status.busy":"2024-03-13T14:00:27.156601Z","iopub.execute_input":"2024-03-13T14:00:27.157528Z","iopub.status.idle":"2024-03-13T14:00:27.165294Z","shell.execute_reply.started":"2024-03-13T14:00:27.157494Z","shell.execute_reply":"2024-03-13T14:00:27.164489Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"for epoch in range(num_epochs):\n    model.train()\n    loss = 0\n    for data in trainloader:\n        data = data.to(device)\n        optimizer.zero_grad()\n        out = model(data.x, data.edge_index)\n        loss_ = criterion(out, data.y)\n        loss_.backward()\n        optimizer.step()\n        loss += loss_.item()\n    exp_lr_scheduler.step()\n    loss/=len(train)\n    tr_acc = accuracy(model, trainloader2)\n    te_acc = accuracy(model, testloader)\n    loss_ep.append(loss)\n    tr_acc_ep.append(tr_acc)\n    te_acc_ep.append(te_acc)\n    print(f'Epoch [{epoch+1}/{num_epochs}] Loss: {loss:.10f}, Train Acc: {tr_acc:.6f}, Test Acc: {te_acc:.6f}')\n\nresult = np.array([loss_ep, tr_acc_ep, te_acc_ep]).T\nnp.savetxt(outpath+f'{type(model.layer1).__name__}{len(model.layer2)+1}_loss_tracc_teacc_{lr}_{num_epochs}_{step_size}_{gamma}.txt', result)\nmax_idx = result[:,2].argmax()\nprint(f'\\nMax Test Accuracy at Epoch {max_idx+1}: {result[max_idx]}\\n')","metadata":{"execution":{"iopub.status.busy":"2024-03-13T14:00:28.338070Z","iopub.execute_input":"2024-03-13T14:00:28.338730Z","iopub.status.idle":"2024-03-13T14:08:53.829587Z","shell.execute_reply.started":"2024-03-13T14:00:28.338697Z","shell.execute_reply":"2024-03-13T14:08:53.827839Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"Epoch [1/100] Loss: 0.0103120983, Train Acc: 0.686603, Test Acc: 0.661925\nEpoch [2/100] Loss: 0.0053608867, Train Acc: 0.837714, Test Acc: 0.828107\nEpoch [3/100] Loss: 0.0035846410, Train Acc: 0.908621, Test Acc: 0.905357\nEpoch [4/100] Loss: 0.0028046822, Train Acc: 0.928915, Test Acc: 0.927699\nEpoch [5/100] Loss: 0.0023206334, Train Acc: 0.930860, Test Acc: 0.929090\nEpoch [6/100] Loss: 0.0020018263, Train Acc: 0.960595, Test Acc: 0.957125\nEpoch [7/100] Loss: 0.0017743699, Train Acc: 0.968228, Test Acc: 0.962933\nEpoch [8/100] Loss: 0.0015978763, Train Acc: 0.969792, Test Acc: 0.964692\nEpoch [9/100] Loss: 0.0014520910, Train Acc: 0.978638, Test Acc: 0.975867\nEpoch [10/100] Loss: 0.0013296424, Train Acc: 0.966962, Test Acc: 0.964864\nEpoch [11/100] Loss: 0.0012259405, Train Acc: 0.980303, Test Acc: 0.977724\nEpoch [12/100] Loss: 0.0011391878, Train Acc: 0.980260, Test Acc: 0.977609\nEpoch [13/100] Loss: 0.0010739597, Train Acc: 0.978769, Test Acc: 0.976300\nEpoch [14/100] Loss: 0.0010222259, Train Acc: 0.986662, Test Acc: 0.984203\nEpoch [15/100] Loss: 0.0009735220, Train Acc: 0.978883, Test Acc: 0.976055\nEpoch [16/100] Loss: 0.0009349416, Train Acc: 0.985430, Test Acc: 0.982960\nEpoch [17/100] Loss: 0.0008977362, Train Acc: 0.985220, Test Acc: 0.982886\nEpoch [18/100] Loss: 0.0008677801, Train Acc: 0.984536, Test Acc: 0.982600\nEpoch [19/100] Loss: 0.0008380119, Train Acc: 0.984757, Test Acc: 0.982436\nEpoch [20/100] Loss: 0.0008196034, Train Acc: 0.984846, Test Acc: 0.982681\nEpoch [21/100] Loss: 0.0007881123, Train Acc: 0.985654, Test Acc: 0.983549\nEpoch [22/100] Loss: 0.0007715779, Train Acc: 0.985430, Test Acc: 0.982960\nEpoch [23/100] Loss: 0.0007606107, Train Acc: 0.986879, Test Acc: 0.985005\nEpoch [24/100] Loss: 0.0007496783, Train Acc: 0.986219, Test Acc: 0.984228\nEpoch [25/100] Loss: 0.0007413049, Train Acc: 0.985832, Test Acc: 0.983598\nEpoch [26/100] Loss: 0.0007347505, Train Acc: 0.988367, Test Acc: 0.985995\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","Cell \u001b[0;32mIn[16], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m      3\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m data \u001b[38;5;129;01min\u001b[39;00m trainloader:\n\u001b[1;32m      5\u001b[0m     data \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m      6\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:674\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    672\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    673\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 674\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    675\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    676\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:54\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n\u001b[0;32m---> 54\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollate_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch_geometric/loader/dataloader.py:27\u001b[0m, in \u001b[0;36mCollater.__call__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m     25\u001b[0m elem \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, BaseData):\n\u001b[0;32m---> 27\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mBatch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_data_list\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfollow_batch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfollow_batch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     30\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexclude_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexclude_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     31\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(elem, torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m default_collate(batch)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch_geometric/data/batch.py:97\u001b[0m, in \u001b[0;36mBatch.from_data_list\u001b[0;34m(cls, data_list, follow_batch, exclude_keys)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfrom_data_list\u001b[39m(\n\u001b[1;32m     84\u001b[0m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     87\u001b[0m     exclude_keys: Optional[List[\u001b[38;5;28mstr\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     88\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Self:\n\u001b[1;32m     89\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Constructs a :class:`~torch_geometric.data.Batch` object from a\u001b[39;00m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;124;03m    list of :class:`~torch_geometric.data.Data` or\u001b[39;00m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;124;03m    :class:`~torch_geometric.data.HeteroData` objects.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     95\u001b[0m \u001b[38;5;124;03m    Will exclude any keys given in :obj:`exclude_keys`.\u001b[39;00m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 97\u001b[0m     batch, slice_dict, inc_dict \u001b[38;5;241m=\u001b[39m \u001b[43mcollate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     98\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     99\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdata_list\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdata_list\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    100\u001b[0m \u001b[43m        \u001b[49m\u001b[43mincrement\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    101\u001b[0m \u001b[43m        \u001b[49m\u001b[43madd_batch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43misinstance\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata_list\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mBatch\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    102\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfollow_batch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_batch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    103\u001b[0m \u001b[43m        \u001b[49m\u001b[43mexclude_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mexclude_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    104\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    106\u001b[0m     batch\u001b[38;5;241m.\u001b[39m_num_graphs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(data_list)  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n\u001b[1;32m    107\u001b[0m     batch\u001b[38;5;241m.\u001b[39m_slice_dict \u001b[38;5;241m=\u001b[39m slice_dict  \u001b[38;5;66;03m# type: ignore\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch_geometric/data/collate.py:142\u001b[0m, in \u001b[0;36mcollate\u001b[0;34m(cls, data_list, increment, add_batch, follow_batch, exclude_keys)\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[38;5;66;03m# In case of node-level storages, we add a top-level batch vector it:\u001b[39;00m\n\u001b[1;32m    140\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (add_batch \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(stores[\u001b[38;5;241m0\u001b[39m], NodeStorage)\n\u001b[1;32m    141\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m stores[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mcan_infer_num_nodes):\n\u001b[0;32m--> 142\u001b[0m     repeats \u001b[38;5;241m=\u001b[39m [store\u001b[38;5;241m.\u001b[39mnum_nodes \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m store \u001b[38;5;129;01min\u001b[39;00m stores]\n\u001b[1;32m    143\u001b[0m     out_store\u001b[38;5;241m.\u001b[39mbatch \u001b[38;5;241m=\u001b[39m repeat_interleave(repeats, device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[1;32m    144\u001b[0m     out_store\u001b[38;5;241m.\u001b[39mptr \u001b[38;5;241m=\u001b[39m cumsum(torch\u001b[38;5;241m.\u001b[39mtensor(repeats, device\u001b[38;5;241m=\u001b[39mdevice))\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch_geometric/data/collate.py:142\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    139\u001b[0m \u001b[38;5;66;03m# In case of node-level storages, we add a top-level batch vector it:\u001b[39;00m\n\u001b[1;32m    140\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (add_batch \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(stores[\u001b[38;5;241m0\u001b[39m], NodeStorage)\n\u001b[1;32m    141\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m stores[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mcan_infer_num_nodes):\n\u001b[0;32m--> 142\u001b[0m     repeats \u001b[38;5;241m=\u001b[39m [\u001b[43mstore\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_nodes\u001b[49m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m store \u001b[38;5;129;01min\u001b[39;00m stores]\n\u001b[1;32m    143\u001b[0m     out_store\u001b[38;5;241m.\u001b[39mbatch \u001b[38;5;241m=\u001b[39m repeat_interleave(repeats, device\u001b[38;5;241m=\u001b[39mdevice)\n\u001b[1;32m    144\u001b[0m     out_store\u001b[38;5;241m.\u001b[39mptr \u001b[38;5;241m=\u001b[39m cumsum(torch\u001b[38;5;241m.\u001b[39mtensor(repeats, device\u001b[38;5;241m=\u001b[39mdevice))\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch_geometric/data/storage.py:425\u001b[0m, in \u001b[0;36mNodeStorage.num_nodes\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    423\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m key, value \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m    424\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, Tensor) \u001b[38;5;129;01mand\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m N_KEYS:\n\u001b[0;32m--> 425\u001b[0m         cat_dim \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parent\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__cat_dim__\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    426\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m value\u001b[38;5;241m.\u001b[39msize(cat_dim)\n\u001b[1;32m    427\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, np\u001b[38;5;241m.\u001b[39mndarray) \u001b[38;5;129;01mand\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m N_KEYS:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch_geometric/data/data.py:647\u001b[0m, in \u001b[0;36mData.__cat_dim__\u001b[0;34m(self, key, value, *args, **kwargs)\u001b[0m\n\u001b[1;32m    646\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__cat_dim__\u001b[39m(\u001b[38;5;28mself\u001b[39m, key: \u001b[38;5;28mstr\u001b[39m, value: Any, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m--> 647\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mis_sparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124madj\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m key:\n\u001b[1;32m    648\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m (\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    649\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;129;01min\u001b[39;00m key \u001b[38;5;129;01mor\u001b[39;00m key \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mface\u001b[39m\u001b[38;5;124m'\u001b[39m:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch_geometric/utils/sparse.py:140\u001b[0m, in \u001b[0;36mis_sparse\u001b[0;34m(src)\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mis_sparse\u001b[39m(src: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mbool\u001b[39m:\n\u001b[1;32m    133\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Returns :obj:`True` if the input :obj:`src` is of type\u001b[39;00m\n\u001b[1;32m    134\u001b[0m \u001b[38;5;124;03m    :class:`torch.sparse.Tensor` (in any sparse layout) or of type\u001b[39;00m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;124;03m    :class:`torch_sparse.SparseTensor`.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    138\u001b[0m \u001b[38;5;124;03m        src (Any): The input object to be checked.\u001b[39;00m\n\u001b[1;32m    139\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 140\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mis_torch_sparse_tensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43msrc\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(src, SparseTensor)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch_geometric/utils/sparse.py:122\u001b[0m, in \u001b[0;36mis_torch_sparse_tensor\u001b[0;34m(src)\u001b[0m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Returns :obj:`True` if the input :obj:`src` is a\u001b[39;00m\n\u001b[1;32m    116\u001b[0m \u001b[38;5;124;03m:class:`torch.sparse.Tensor` (in any sparse layout).\u001b[39;00m\n\u001b[1;32m    117\u001b[0m \n\u001b[1;32m    118\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[1;32m    119\u001b[0m \u001b[38;5;124;03m    src (Any): The input object to be checked.\u001b[39;00m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    121\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(src, Tensor):\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m src\u001b[38;5;241m.\u001b[39mlayout \u001b[38;5;241m==\u001b[39m torch\u001b[38;5;241m.\u001b[39msparse_coo:\n\u001b[1;32m    123\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m src\u001b[38;5;241m.\u001b[39mlayout \u001b[38;5;241m==\u001b[39m torch\u001b[38;5;241m.\u001b[39msparse_csr:\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "],"ename":"KeyboardInterrupt","evalue":"","output_type":"error"}]},{"cell_type":"code","source":"# Save the trained model\ntorch.save(model.state_dict(), 'MLP_vastu_trained_model.pth')","metadata":{"execution":{"iopub.status.busy":"2024-03-13T14:09:00.941217Z","iopub.execute_input":"2024-03-13T14:09:00.941586Z","iopub.status.idle":"2024-03-13T14:09:00.949443Z","shell.execute_reply.started":"2024-03-13T14:09:00.941556Z","shell.execute_reply":"2024-03-13T14:09:00.948506Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"# Load the saved model\nloaded_model = Model(layer_type=models[model_type], n_hidden=hidden_layers)\nloaded_model.load_state_dict(torch.load('MLP_vastu_trained_model.pth'))\nloaded_model.eval()","metadata":{"execution":{"iopub.status.busy":"2024-03-13T14:09:05.864491Z","iopub.execute_input":"2024-03-13T14:09:05.864861Z","iopub.status.idle":"2024-03-13T14:09:05.875892Z","shell.execute_reply.started":"2024-03-13T14:09:05.864834Z","shell.execute_reply":"2024-03-13T14:09:05.875009Z"},"trusted":true},"execution_count":18,"outputs":[{"execution_count":18,"output_type":"execute_result","data":{"text/plain":"Model(\n  (layer1): Linear(in_features=2, out_features=16, bias=True)\n  (layer2): ModuleList(\n    (0): Linear(in_features=16, out_features=16, bias=True)\n  )\n  (classifier): Linear(in_features=16, out_features=8, bias=True)\n)"},"metadata":{}}]},{"cell_type":"code","source":"new_features=dataset.get(80000)","metadata":{"execution":{"iopub.status.busy":"2024-03-13T14:09:08.415164Z","iopub.execute_input":"2024-03-13T14:09:08.415522Z","iopub.status.idle":"2024-03-13T14:09:08.421228Z","shell.execute_reply.started":"2024-03-13T14:09:08.415492Z","shell.execute_reply":"2024-03-13T14:09:08.420268Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"new_features.x","metadata":{"execution":{"iopub.status.busy":"2024-03-13T14:09:09.593019Z","iopub.execute_input":"2024-03-13T14:09:09.593426Z","iopub.status.idle":"2024-03-13T14:09:09.615250Z","shell.execute_reply.started":"2024-03-13T14:09:09.593394Z","shell.execute_reply":"2024-03-13T14:09:09.614240Z"},"trusted":true},"execution_count":20,"outputs":[{"execution_count":20,"output_type":"execute_result","data":{"text/plain":"tensor([[ 2.,  7.],\n        [ 0.,  2.],\n        [ 7.,  7.],\n        [ 3.,  2.],\n        [ 1.,  5.],\n        [ 6.,  1.],\n        [ 9.,  4.],\n        [13.,  8.]])"},"metadata":{}}]},{"cell_type":"code","source":"with torch.no_grad():\n    x, edge_index = new_features.x, new_features.edge_index\n    new_predictions = loaded_model(x,_)","metadata":{"execution":{"iopub.status.busy":"2024-03-13T14:09:11.963279Z","iopub.execute_input":"2024-03-13T14:09:11.963640Z","iopub.status.idle":"2024-03-13T14:09:11.983149Z","shell.execute_reply.started":"2024-03-13T14:09:11.963610Z","shell.execute_reply":"2024-03-13T14:09:11.982372Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"new_predictions","metadata":{"execution":{"iopub.status.busy":"2024-03-13T14:09:13.238128Z","iopub.execute_input":"2024-03-13T14:09:13.239233Z","iopub.status.idle":"2024-03-13T14:09:13.247213Z","shell.execute_reply.started":"2024-03-13T14:09:13.239189Z","shell.execute_reply":"2024-03-13T14:09:13.246097Z"},"trusted":true},"execution_count":22,"outputs":[{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"tensor([[-3.7322e+01, -3.0329e+00,  1.6225e+00, -3.8140e-01,  2.5706e+00,\n          7.6669e-01,  6.3794e+00, -1.1791e+01],\n        [ 2.0634e+00,  1.6316e+00, -1.6300e+01, -9.1547e+00,  2.0579e+01,\n          4.1143e+01,  4.5357e-01, -4.9522e+01],\n        [ 5.9315e-01, -4.7215e+01, -1.1871e+01, -4.1504e+01, -1.6378e+01,\n          2.7712e+00, -4.1816e-01,  9.5246e+00],\n        [-7.1701e+00, -1.6063e+01, -4.2560e+00,  1.4914e+01,  4.1397e+00,\n          1.0850e+01,  1.0369e+00, -1.4505e+01],\n        [-1.4027e+01, -1.9411e+01, -1.4970e+01,  8.7546e-02,  7.1083e+00,\n         -3.7519e+00,  6.7413e-01,  1.2623e+01],\n        [-3.3779e+01, -9.9618e+01, -1.6946e+01,  4.0066e+00,  1.2764e+01,\n          1.7280e+01,  1.1032e+01, -2.0677e+01],\n        [ 2.2115e+00,  2.9220e+00,  8.1114e+00,  2.5643e+00, -1.0832e+00,\n         -9.3924e+00, -5.5619e+00, -3.2335e+01],\n        [-1.9260e+01, -8.5642e+01, -1.7652e+01, -3.8800e+01, -1.9710e+01,\n          3.5418e-01, -3.4825e+00, -4.9410e+00]])"},"metadata":{}}]},{"cell_type":"code","source":"# Assuming new_predictions is your tensor\npredicted_categories = new_predictions.argmax(dim=1)\nprint(predicted_categories)","metadata":{"execution":{"iopub.status.busy":"2024-03-13T14:09:15.973582Z","iopub.execute_input":"2024-03-13T14:09:15.974437Z","iopub.status.idle":"2024-03-13T14:09:15.980417Z","shell.execute_reply.started":"2024-03-13T14:09:15.974403Z","shell.execute_reply":"2024-03-13T14:09:15.979466Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"tensor([6, 5, 7, 3, 7, 5, 2, 5])\n","output_type":"stream"}]},{"cell_type":"code","source":"([6, 5, 7, 3, 7, 5, 2, 5])","metadata":{"execution":{"iopub.status.busy":"2024-03-13T14:09:18.412200Z","iopub.execute_input":"2024-03-13T14:09:18.412934Z","iopub.status.idle":"2024-03-13T14:09:18.420152Z","shell.execute_reply.started":"2024-03-13T14:09:18.412905Z","shell.execute_reply":"2024-03-13T14:09:18.419271Z"},"trusted":true},"execution_count":24,"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"[6, 5, 7, 3, 7, 5, 2, 5]"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}